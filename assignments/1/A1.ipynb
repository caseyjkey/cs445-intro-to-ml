{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1.1 Linear Regression with SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A1.1: *Added preliminary grading script in last cells of notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will implement three functions `train`, `use`, and `rmse` and apply them to some weather data.\n",
    "Here are the specifications for these functions, which you must satisfy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model = train(X, T, learning_rate, n_epochs, verbose)`\n",
    "* `X`: is an $N$ x $D$ matrix of input data samples, one per row. $N$ is the number of samples and $D$ is the number of variable values in\n",
    "each sample.\n",
    "* `T`: is an $N$ x $K$ matrix of desired target values for each sample.  $K$ is the number of output values you want to predict for each sample.\n",
    "* `learning_rate`: is a scalar that controls the step size of each update to the weight values.\n",
    "* `n_epochs`: is the number of epochs, or passes, through all $N$ samples, to take while updating the weight values.\n",
    "* `verbose`: is True or False (default value) to control whether or not occasional text is printed to show the training progress.\n",
    "* `model`: is the returned value, which must be a dictionary with the keys `'w'`, `'Xmeans'`, `'Xstds'`, `'Tmeans'` and `'Tstds'`.\n",
    "\n",
    "`Y = use(X, model)`\n",
    "* `X`: is an $N$ x $D$ matrix of input data samples, one per row, for which you want to predict the target values.\n",
    "* `model`: is the dictionary returned by `train`.\n",
    "* `Y`: is the returned $N$ x $K$ matrix of predicted values, one for each sample in `X`.\n",
    "\n",
    "`result = rmse(Y, T)`\n",
    "* `Y`: is an $N$ x $K$ matrix of predictions produced by `use`.\n",
    "* `T`: is the $N$ x $K$ matrix of target values.\n",
    "* `result`: is a scalar calculated as the square root of the mean of the squared differences between each sample (row) in `Y` and `T`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get you started, here are the standard imports we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 60 points: 40 for train, 10 for use, 10 for rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here is a start at defining the `train`, `use`, and `rmse`\n",
    "functions.  Fill in the correct code wherever you see `. . .` with\n",
    "one or more lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train(X, T, learning_rate, n_epochs, verbose=False):\n",
    "    \n",
    "    X1 = np.insert(X, 0, 1, axis=1)\n",
    "    \n",
    "    Xstds = np.std(X1[:, 1:], axis=0)\n",
    "    Tstds = np.std(T[:], axis=0)\n",
    "\n",
    "    Xmeans = np.mean(X1[:, 1:], axis=0)\n",
    "    Tmeans = np.mean(T[:], axis=0)\n",
    "    \n",
    "    X1 = X1.astype(float)\n",
    "    T = T.astype(float)\n",
    "\n",
    "    X1[:, 1:] = (X1[:, 1:] - Xmeans) / Xstds\n",
    "    T[:] = (T[:] - Tmeans) / Tstds\n",
    "        \n",
    "    n_samples, n_inputs = X1.shape  # number of rows in data equals the number of samples\n",
    "    w = np.zeros((n_inputs, 1)) \n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        sqerror_sum = 0\n",
    "\n",
    "        for n in range(n_samples):\n",
    "\n",
    "            # Use current weight values to predict output for sample n, then\n",
    "            # calculate the error, and\n",
    "            # update the weight values.\n",
    "            #. . .\n",
    "            y = X1[n:n + 1, :] @ w      # predicted value, y, for sample n\n",
    "            error = T[n:n + 1, :] - y  \n",
    "            # update weights by fraction of negative derivative of square error with respect to weights\n",
    "            # print(y.shape, error.shape, (X1[n:n+1,:].T * error).shape)\n",
    "            w += learning_rate * X1[n:n + 1, :].T * error\n",
    "            sqerror_sum += error ** 2\n",
    "            \n",
    "            # Add the squared error to sqerror_sum\n",
    "            # . . .\n",
    "        if verbose and (n_epochs < 11 or (epoch + 1) % (n_epochs // 10) == 0):\n",
    "            rmse = np.sqrt(sqerror_sum / n_samples)\n",
    "            rmse = rmse[0, 0]  # because rmse is 1x1 matrix\n",
    "            print(f'Epoch {epoch + 1} RMSE {rmse:.2f}')\n",
    "                \n",
    "\n",
    "    return {'w': w, 'Xmeans': Xmeans, 'Xstds': Xstds,\n",
    "            'Tmeans': Tmeans, 'Tstds': Tstds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def use(X, model):\n",
    "    # Standardize X using Xmeans and Xstds in model\n",
    "    Xstds = np.std(X1[:, 1:], axis=0)\n",
    "    Xmeans = np.mean(X1[:, 1:], axis=0)\n",
    "    Y = X1 @ model['w']\n",
    "    Xtds = Xstds.astype(float)\n",
    "    Xmeans = Xmeans.astype(float)\n",
    "    # Predict output values using weights in model\n",
    "    \n",
    "    \n",
    "    # Unstandardize the predicted output values using Tmeans and Tstds in model\n",
    "    Y = (Y[:]* model['Tstds']) + model['Tmeans'] \n",
    "    # Return the unstandardized output values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def rmse(A, B):\n",
    "    rmseTrain = np.sqrt(np.mean((A @ w - B)**2, axis=0))\n",
    "    print(rmseTrain)\n",
    "    return rmseTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a simple example use of your functions to help you debug them.  Your functions must produce the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.arange(0, 100).reshape(-1, 1)  # make X a 100 x 1 matrix\n",
    "T = 0.5 + 0.3 * X + 0.005 * (X - 50) ** 2\n",
    "plt.plot(X, T, '.')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('T');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 RMSE 1.00\n",
      "Epoch 10 RMSE 0.99\n",
      "Epoch 15 RMSE 0.99\n",
      "Epoch 20 RMSE 0.98\n",
      "Epoch 25 RMSE 0.98\n",
      "Epoch 30 RMSE 0.98\n",
      "Epoch 35 RMSE 0.97\n",
      "Epoch 40 RMSE 0.97\n",
      "Epoch 45 RMSE 0.97\n",
      "Epoch 50 RMSE 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'w': array([[3.7286816e-06],\n",
       "        [3.8912160e-02]]),\n",
       " 'Xmeans': array([5.375]),\n",
       " 'Xstds': array([3.35177192]),\n",
       " 'Tmeans': array([0.055]),\n",
       " 'Tstds': array([0.14136124])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = train(X, T, 0.0001, 50, verbose=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'use' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/CS445/A1grader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'use' is not defined"
     ]
    }
   ],
   "source": [
    "Y = use(X, model)\n",
    "plt.plot(T, '.', label='T')\n",
    "plt.plot(Y, '.', label='Y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Y[:, 0], T[:, 0], 'o')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "a = max(min(Y[:, 0]), min(T[:, 0]))\n",
    "b = min(max(Y[:, 0]), max(T[:, 0]))\n",
    "plt.plot([a, b], [a, b], 'r', linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that your functions are working, we can apply them to some real data. We will use data\n",
    "from  [CSU's CoAgMet Station Daily Data Access](http://coagmet.colostate.edu/cgi-bin/dailydata_form.pl).\n",
    "\n",
    "You can get the data file [here](http://www.cs.colostate.edu/~cs445/notebooks/A1_data.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 points:\n",
    "\n",
    "Read in the data into variable `df` using `pandas.read_csv` like we did in lecture notes.\n",
    "Missing values in this dataset are indicated by the string `'***'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('https://www.cs.colostate.edu/~cs445/notebooks/A1_data.txt',header=None, delim_whitespace=True)\n",
    "df\n",
    "#df.iloc[280:290] # look at rows 30-39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 points:\n",
    "\n",
    "Check for missing values by showing the number of NA values, as shown in lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('https://www.cs.colostate.edu/~cs445/notebooks/A1_data.txt',header=None, delim_whitespace=True, na_values='?')\n",
    "df\n",
    "df.isna().sum() # detect missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 points:\n",
    "\n",
    "If there are missing values, remove either samples or features that contain missing values. Prove that you\n",
    "were successful by counting the number of missing values now, which should be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()\n",
    "df.isnull().all(axis = 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your job is now to create a linear model that predicts the next day's average temperature (tave) from the previous day's values. A discription of all features can be found [here](https://coagmet.colostate.edu/rawdata_docs.php). To start, consider just focusing on these features: \n",
    "1. tave: average temperature\n",
    "2. tmax: maximum temperature\n",
    "3. tmin: minimum temperature\n",
    "4. vp: vapor pressure\n",
    "5. rhmax: maximum relative humidity\n",
    "6. rhmin: minimum relative humidity\n",
    "7. pp: precipitation\n",
    "8. gust: wind gust speed\n",
    "\n",
    "First, modify the datafile to add a new column: 'next tave' -- here's a hint on your X and T vectors names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnames = ['tave', 'tmax', 'tmin', 'vp', 'rhmax', 'rhmin', 'pp', 'gust']\n",
    "Tnames = ['next tave']\n",
    "\n",
    "Xnames = np.insert(Tnames, 8, 0, 1)\n",
    "#X1 = np.insert(X, 0, 1, 1)\n",
    "#np.insert(array, where, value, axis) \n",
    "# where = index?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 points:\n",
    "\n",
    "Now select those eight columns from `df` and convert the result to a `numpy` array.  (Easier than it sounds.)\n",
    "Then assign `X` to be all columns and all but the last row.  Assign `T` to be just the first column (tave) and all but the first sample.  So now the first row (sample) in `X` is associated with the first row (sample) in `T` which tave for the following day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 points:\n",
    "\n",
    "Use the function `train` to train a model for the `X`\n",
    "and `T` data.  Run it several times with different `learning_rate`\n",
    "and `n_epochs` values to produce decreasing errors. Use the `use`\n",
    "function and plots of `T` versus predicted `Y` values to show how\n",
    "well the model is working.  Type your observations of the plot and of the value of `rmse` to discuss how well the model succeeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 points:\n",
    "\n",
    "Print the weight values in the resulting model along with their corresponding variable names (in `Xnames`). Use the relative magnitude\n",
    "of the weight values to discuss which input variables are most significant in predicting the changes in the tave values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading and Check-in\n",
    "\n",
    "Your notebook will be partially graded automatically.  You can test this grading process yourself by downloading [A1grader.zip](https://www.cs.colostate.edu/~cs445/notebooks/A1grader.zip) and extract `A1grader.py` parallel to this notebook.  Run the code in the in the following cell to see an example grading run.  If your functions are defined correctly, you should see a score of 60/60.  The remaining 40 points are based on testing other data and your discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= Code Execution =======================\n",
      "\n",
      "Extracting python code from notebook named 'A1.1 Linear Regression with SGD.ipynb' and storing in notebookcode.py\n",
      "Removing all statements that are not function or class defs or import statements.\n",
      "CRITICAL ERROR: Function named 'use' is not defined\n",
      "  Check the spelling and capitalization of the function name.\n",
      "\n",
      "Testing\n",
      "  X = np.array([1, 2, 3, 4, 5, 8, 9, 11]).reshape((-1, 1))\n",
      "  T = (X - 5) * 0.05 + 0.002 * (X - 8)**2\n",
      "  model = train(X, T, 0.001, 1000, True)\n",
      "\n",
      "Epoch 100 RMSE 0.46\n",
      "Epoch 200 RMSE 0.24\n",
      "Epoch 300 RMSE 0.15\n",
      "Epoch 400 RMSE 0.13\n",
      "Epoch 500 RMSE 0.13\n",
      "Epoch 600 RMSE 0.12\n",
      "Epoch 700 RMSE 0.12\n",
      "Epoch 800 RMSE 0.12\n",
      "Epoch 900 RMSE 0.12\n",
      "Epoch 1000 RMSE 0.12\n",
      "\n",
      "--- 20/20 points. Returned correct values.\n",
      "\n",
      "--- 10/10 points. Xmeans and Xstds are correct values.\n",
      "\n",
      "--- 10/10 points. Tmeans and Tstds are correct values.\n",
      "\n",
      "Testing\n",
      "  Y = use(X, model)\n",
      "\n",
      "\n",
      "--- 0/10 points. use raised the exception\n",
      "\n",
      "name 'use' is not defined\n",
      "\n",
      "Testing\n",
      "  err = rmse(Y, T)\n",
      "\n",
      "\n",
      "--- 0/10 points. rmse raised the exception\n",
      "\n",
      "name 'Y' is not defined\n",
      "\n",
      "======================================================================\n",
      "CS445 Execution Grade is 40 / 60\n",
      "======================================================================\n",
      "\n",
      " __ / 5 Reading in weather.data correctly.\n",
      "\n",
      " __ / 5 Count missing values, to show there are some.\n",
      "\n",
      " __ / 5 Remove samples with missing values. Count to show there are none.\n",
      "\n",
      " __ / 5 Construct X and T matrices as specified.\n",
      "\n",
      " __ / 15 Use your train function on X and T. Show results as RMSE values and as plots\n",
      "       for several different values of learning_rate and n_epochs. Type your \n",
      "       observations of RMSE values and of plots with at least five sentences.\n",
      "\n",
      " __ / 5 Print the weight values with corresponding variable names. Discuss\n",
      "       which input variablesa re most signficant in predicting tave values.\n",
      "\n",
      "======================================================================\n",
      "CS445 FINAL GRADE is  _  / 100\n",
      "======================================================================\n",
      "\n",
      "Extra Credit:\n",
      "Predict the change in tave from one day to the next, instead of the actual tave.\n",
      "Show and discuss RMSE and plotting results for several values of learning_rate\n",
      "and n_epochs.\n",
      "\n",
      "CS445 EXTRA CREDIT is 0 / 1\n"
     ]
    }
   ],
   "source": [
    "%run -i A1grader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different but similar grading script will be used to grade yout checked-in notebook.  It will include different tests.\n",
    "\n",
    "You must name your notebook as `Lastname-A1.ipynb` with `Lastname` being your last name, and then save this notebook and check it in at the A1 assignment link in our Canvas web page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: 1 point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical problem when predicting the next value in a time series is\n",
    "that the best solution may be to predict the previous value.  The\n",
    "predicted value will look a lot like the input tave value shifted on\n",
    "time step later.\n",
    "\n",
    "To do better, try predicting the change in tave from one day to the next. `T` can be assigned as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/CS445/A1grader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m  \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "T = data[1:, 0:1] -  data[:-1, 0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now repeat the training experiments to pick good `learning_rate` and\n",
    "`n_epochs`.  Use predicted values to produce next day tave values by\n",
    "adding the predicted values to the previous day's tave.  Use `rmse`\n",
    "to determine if this way of predicting next tave is better than\n",
    "directly predicting tave."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
